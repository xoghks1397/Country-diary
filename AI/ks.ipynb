{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "try:\n",
    "    collectionsAbc = collections.abc\n",
    "except AttributeError:\n",
    "    collectionsAbc = collections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 멀티라벨 분류 **\n",
    "\n",
    "비행기, 불상, 나비, 게 4가지의 이미지를 분류해본다\n",
    "\n",
    "기본적인 방법은 단일 이미지 분류와 같다. 대신, 다중 이미지 분류이기 때문에 카테고리의 변화가 있다.\n",
    "\n",
    "그리고 단일 보다 데이터셋이 현저히 부족하다. 이는 데이터셋을 잘 못모은 내 잘못이다.\n",
    "\n",
    "미리 양해를 구한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blue  파일 길이 :  200\n",
      "blue  :  ./multi_img_data/imgs_others/train/blue\\0000555_SAM_7344.png\n",
      "jumbak  파일 길이 :  200\n",
      "jumbak  :  ./multi_img_data/imgs_others/train/jumbak\\0001073_09103711.png\n",
      "white  파일 길이 :  200\n",
      "white  :  ./multi_img_data/imgs_others/train/white\\0003710_09103516.png\n",
      "gue  파일 길이 :  200\n",
      "gue  :  ./multi_img_data/imgs_others/train/gue\\0016861_20181024_151919.png\n",
      "ipgom  파일 길이 :  200\n",
      "ipgom  :  ./multi_img_data/imgs_others/train/ipgom\\0005478_20181004_152856.png\n",
      "america  파일 길이 :  200\n",
      "america  :  ./multi_img_data/imgs_others/train/america\\0013680_SAM_4606_R.png\n",
      "ok 1200\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os, glob, numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "caltech_dir = \"./multi_img_data/imgs_others/train\"\n",
    "categories = [\"blue\", \"jumbak\", \"white\",\"gue\",\"ipgom\",\"america\"]\n",
    "nb_classes = len(categories)\n",
    "\n",
    "image_w = 64\n",
    "image_h = 64\n",
    "\n",
    "pixels = image_h * image_w * 3\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for idx, cat in enumerate(categories):\n",
    "    \n",
    "    #one-hot 돌리기.\n",
    "    label = [0 for i in range(nb_classes)]\n",
    "    label[idx] = 1\n",
    "\n",
    "    image_dir = caltech_dir + \"/\" + cat\n",
    "    files = glob.glob(image_dir+\"/*.png\")\n",
    "    print(cat, \" 파일 길이 : \", len(files))\n",
    "    for i, f in enumerate(files):\n",
    "        img = Image.open(f)\n",
    "        img = img.convert(\"RGB\")\n",
    "        img = img.resize((image_w, image_h))\n",
    "        data = np.asarray(img)\n",
    "\n",
    "        X.append(data)\n",
    "        y.append(label)\n",
    "\n",
    "        if i % 700 == 0:\n",
    "            print(cat, \" : \", f)\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "#1 0 0 0 이면 airplanes\n",
    "#0 1 0 0 이면 buddha 이런식\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "xy = (X_train, X_test, y_train, y_test)\n",
    "np.save(\"./numpy_data/multi_image_data.npy\", xy)\n",
    "\n",
    "print(\"ok\", len(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pymssql'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-f709edba0dc3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpymssql\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion_info\u001b[0m \u001b[1;33m>=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mimport\u001b[0m \u001b[0mcollections\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabc\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcollections_abc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pymssql'"
     ]
    }
   ],
   "source": [
    "# import pymssql\n",
    "# import sys\n",
    "\n",
    "# if sys.version_info >=(3,3):\n",
    "#     import collections.abc as collections_abc\n",
    "# else:\n",
    "#     import collections as collections_abc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 numpy 데이터를 불러온다. 저것을 가지고 학습!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900, 64, 64, 3)\n",
      "900\n"
     ]
    }
   ],
   "source": [
    "import os, glob, numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "import keras.backend.tensorflow_backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)\n",
    "\n",
    "X_train, X_test, y_train, y_test = np.load('./numpy_data/multi_image_data.npy')\n",
    "print(X_train.shape)\n",
    "print(X_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [\"blue\", \"jumbak\", \"white\",\"gue\",\"ipgom\",\"america\"]\n",
    "nb_classes = len(categories)\n",
    "\n",
    "#일반화\n",
    "X_train = X_train.astype(float) / 255\n",
    "X_test = X_test.astype(float) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with K.tf_ops.device('/device:GPU:0'):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3,3), padding=\"same\", input_shape=X_train.shape[1:], activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Conv2D(64, (3,3), padding=\"same\", activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(nb_classes, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model_dir = './model'\n",
    "    \n",
    "    if not os.path.exists(model_dir):\n",
    "        os.mkdir(model_dir)\n",
    "    \n",
    "    model_path = model_dir + '/multi_img_classification.model'\n",
    "    checkpoint = ModelCheckpoint(filepath=model_path , monitor='val_loss', verbose=1, save_best_only=True)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=6)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 64, 64, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               4194560   \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 4,215,494\n",
      "Trainable params: 4,215,494\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 900 samples, validate on 300 samples\n",
      "Epoch 1/50\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 1.9043 - accuracy: 0.2356 - val_loss: 1.5150 - val_accuracy: 0.4333\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.51497, saving model to ./model/multi_img_classification.model\n",
      "Epoch 2/50\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 1.1490 - accuracy: 0.4989 - val_loss: 1.0611 - val_accuracy: 0.5200\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.51497 to 1.06111, saving model to ./model/multi_img_classification.model\n",
      "Epoch 3/50\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.9278 - accuracy: 0.5922 - val_loss: 0.9273 - val_accuracy: 0.6333\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.06111 to 0.92731, saving model to ./model/multi_img_classification.model\n",
      "Epoch 4/50\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.8228 - accuracy: 0.6478 - val_loss: 0.7360 - val_accuracy: 0.7567\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.92731 to 0.73598, saving model to ./model/multi_img_classification.model\n",
      "Epoch 5/50\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.8223 - accuracy: 0.6533 - val_loss: 0.7310 - val_accuracy: 0.8033\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.73598 to 0.73097, saving model to ./model/multi_img_classification.model\n",
      "Epoch 6/50\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.6858 - accuracy: 0.7067 - val_loss: 0.6060 - val_accuracy: 0.8267\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.73097 to 0.60600, saving model to ./model/multi_img_classification.model\n",
      "Epoch 7/50\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.6209 - accuracy: 0.7722 - val_loss: 0.5510 - val_accuracy: 0.7967\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.60600 to 0.55103, saving model to ./model/multi_img_classification.model\n",
      "Epoch 8/50\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.5640 - accuracy: 0.7533 - val_loss: 0.5408 - val_accuracy: 0.7767\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.55103 to 0.54079, saving model to ./model/multi_img_classification.model\n",
      "Epoch 9/50\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.6012 - accuracy: 0.7811 - val_loss: 0.4828 - val_accuracy: 0.8867\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.54079 to 0.48279, saving model to ./model/multi_img_classification.model\n",
      "Epoch 10/50\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.4294 - accuracy: 0.8644 - val_loss: 0.4101 - val_accuracy: 0.8533\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.48279 to 0.41015, saving model to ./model/multi_img_classification.model\n",
      "Epoch 11/50\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.4229 - accuracy: 0.8467 - val_loss: 0.3910 - val_accuracy: 0.8767\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.41015 to 0.39105, saving model to ./model/multi_img_classification.model\n",
      "Epoch 12/50\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.3693 - accuracy: 0.8644 - val_loss: 0.3240 - val_accuracy: 0.8967\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.39105 to 0.32402, saving model to ./model/multi_img_classification.model\n",
      "Epoch 13/50\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.3401 - accuracy: 0.8911 - val_loss: 0.2865 - val_accuracy: 0.9033\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.32402 to 0.28654, saving model to ./model/multi_img_classification.model\n",
      "Epoch 14/50\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.2701 - accuracy: 0.9089 - val_loss: 0.2764 - val_accuracy: 0.9067\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.28654 to 0.27642, saving model to ./model/multi_img_classification.model\n",
      "Epoch 15/50\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.3014 - accuracy: 0.8900 - val_loss: 0.2729 - val_accuracy: 0.9233\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.27642 to 0.27286, saving model to ./model/multi_img_classification.model\n",
      "Epoch 16/50\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.3269 - accuracy: 0.8922 - val_loss: 0.2573 - val_accuracy: 0.9200\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.27286 to 0.25735, saving model to ./model/multi_img_classification.model\n",
      "Epoch 17/50\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.2202 - accuracy: 0.9344 - val_loss: 0.2404 - val_accuracy: 0.9233\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.25735 to 0.24040, saving model to ./model/multi_img_classification.model\n",
      "Epoch 18/50\n",
      "900/900 [==============================] - 4s 5ms/step - loss: 0.2176 - accuracy: 0.9222 - val_loss: 0.2205 - val_accuracy: 0.9333\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.24040 to 0.22046, saving model to ./model/multi_img_classification.model\n",
      "Epoch 19/50\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.1971 - accuracy: 0.9433 - val_loss: 0.2434 - val_accuracy: 0.9233\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.22046\n",
      "Epoch 20/50\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.2026 - accuracy: 0.9344 - val_loss: 0.1963 - val_accuracy: 0.9300\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.22046 to 0.19626, saving model to ./model/multi_img_classification.model\n",
      "Epoch 21/50\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.1515 - accuracy: 0.9556 - val_loss: 0.2111 - val_accuracy: 0.9133\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.19626\n",
      "Epoch 22/50\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.1314 - accuracy: 0.9522 - val_loss: 0.2354 - val_accuracy: 0.8967\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.19626\n",
      "Epoch 23/50\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.2023 - accuracy: 0.9244 - val_loss: 0.2142 - val_accuracy: 0.9133\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.19626\n",
      "Epoch 24/50\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.2294 - accuracy: 0.9333 - val_loss: 0.2990 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.19626\n",
      "Epoch 25/50\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.1487 - accuracy: 0.9522 - val_loss: 0.1932 - val_accuracy: 0.9367\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.19626 to 0.19325, saving model to ./model/multi_img_classification.model\n",
      "Epoch 26/50\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.1334 - accuracy: 0.9544 - val_loss: 0.1897 - val_accuracy: 0.9300\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.19325 to 0.18972, saving model to ./model/multi_img_classification.model\n",
      "Epoch 27/50\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.1110 - accuracy: 0.9689 - val_loss: 0.1978 - val_accuracy: 0.9200\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.18972\n",
      "Epoch 28/50\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.1043 - accuracy: 0.9556 - val_loss: 0.1848 - val_accuracy: 0.9467\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.18972 to 0.18476, saving model to ./model/multi_img_classification.model\n",
      "Epoch 29/50\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0934 - accuracy: 0.9689 - val_loss: 0.2136 - val_accuracy: 0.9233\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.18476\n",
      "Epoch 30/50\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.1401 - accuracy: 0.9444 - val_loss: 0.1719 - val_accuracy: 0.9367\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.18476 to 0.17192, saving model to ./model/multi_img_classification.model\n",
      "Epoch 31/50\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0917 - accuracy: 0.9744 - val_loss: 0.1878 - val_accuracy: 0.9267\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.17192\n",
      "Epoch 32/50\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0919 - accuracy: 0.9633 - val_loss: 0.1689 - val_accuracy: 0.9367\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.17192 to 0.16895, saving model to ./model/multi_img_classification.model\n",
      "Epoch 33/50\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0742 - accuracy: 0.9789 - val_loss: 0.1799 - val_accuracy: 0.9367\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.16895\n",
      "Epoch 34/50\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0776 - accuracy: 0.9733 - val_loss: 0.1935 - val_accuracy: 0.9367\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.16895\n",
      "Epoch 35/50\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0646 - accuracy: 0.9767 - val_loss: 0.1531 - val_accuracy: 0.9467\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.16895 to 0.15314, saving model to ./model/multi_img_classification.model\n",
      "Epoch 36/50\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0686 - accuracy: 0.9789 - val_loss: 0.1499 - val_accuracy: 0.9500\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.15314 to 0.14989, saving model to ./model/multi_img_classification.model\n",
      "Epoch 37/50\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0693 - accuracy: 0.9744 - val_loss: 0.1695 - val_accuracy: 0.9433\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.14989\n",
      "Epoch 38/50\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0607 - accuracy: 0.9822 - val_loss: 0.1892 - val_accuracy: 0.9233\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.14989\n",
      "Epoch 39/50\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0594 - accuracy: 0.9789 - val_loss: 0.1993 - val_accuracy: 0.9267\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.14989\n",
      "Epoch 40/50\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0539 - accuracy: 0.9844 - val_loss: 0.2319 - val_accuracy: 0.9233\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.14989\n",
      "Epoch 41/50\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.1650 - accuracy: 0.9444 - val_loss: 0.2323 - val_accuracy: 0.9233\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.14989\n",
      "Epoch 42/50\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.1090 - accuracy: 0.9678 - val_loss: 0.1539 - val_accuracy: 0.9400\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.14989\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#데이터셋이 적어서 validation을 그냥 test 데이터로 했습니다. \n",
    "#데이터셋이 충분하시면 이렇게 하시지 마시고 validation_split=0.2 이렇게 하셔서 테스트 셋으로 나누시길 권장합니다.\n",
    "history = model.fit(X_train, y_train, batch_size=32, epochs=50, validation_data=(X_test, y_test), callbacks=[checkpoint, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 880us/step\n",
      "정확도 : 95.00%%\n"
     ]
    }
   ],
   "source": [
    "print(\"정확도 : %.2f\" % (model.evaluate(X_test, y_test)[1]*100) +\"%%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_vloss = history.history['val_loss']\n",
    "y_loss = history.history['loss']\n",
    "\n",
    "x_len = np.arange(len(y_loss))\n",
    "\n",
    "plt.plot(x_len, y_vloss, marker='.', c='red', label='val_set_loss')\n",
    "plt.plot(x_len, y_loss, marker='.', c='blue', label='train_set_oss')\n",
    "plt.legend()\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.000 0.000 0.000 1.000 0.000 0.000]\n",
      "3\n",
      "해당 image0.png이미지는 토마토_궤양병일 확률이 100.00%로 진단됩니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\multicampus\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:81: DeprecationWarning: update is deprecated. Use replace_one, update_one or update_many instead.\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os, glob, numpy as np\n",
    "from keras.models import load_model\n",
    "\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# client = MongoClient(\"k4a305.p.ssafy.io:27017\")\n",
    "# db = client.test\n",
    "# collection = db.diagnosis\n",
    "\n",
    "client = MongoClient('k4a305.p.ssafy.io', 27017)\n",
    "db = client['27017']\n",
    "collection = db.diagnosis\n",
    "\n",
    "caltech_dir = \"./multi_img_data/imgs_others/test\"\n",
    "image_w = 64\n",
    "image_h = 64\n",
    "\n",
    "pixels = image_h * image_w * 3\n",
    "\n",
    "X = []\n",
    "filenames = []\n",
    "files = glob.glob(caltech_dir+\"/*.*\")\n",
    "for i, f in enumerate(files):\n",
    "    img = Image.open(f)\n",
    "    img = img.convert(\"RGB\")\n",
    "    img = img.resize((image_w, image_h))\n",
    "    data = np.asarray(img)\n",
    "    filenames.append(f)\n",
    "    X.append(data)\n",
    "\n",
    "X = np.array(X)\n",
    "model = load_model('./model/multi_img_classification.model')\n",
    "\n",
    "prediction = model.predict(X)\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})\n",
    "cnt = 0\n",
    "\n",
    "#이 비교는 그냥 파일들이 있으면 해당 파일과 비교. 카테고리와 함께 비교해서 진행하는 것은 _4 파일.\n",
    "for i in prediction:\n",
    "    pre_ans = i.argmax()  # 예측 레이블\n",
    "    print(i)\n",
    "    print(pre_ans)\n",
    "#     \"blue\", \"jumbak\", \"white\",\"gue\",\"ipgom\",\"america\"\n",
    "    pre_ans_str = ''\n",
    "    if pre_ans == 0: pre_ans_str = \"장미_청벌레병\"\n",
    "    elif pre_ans == 1: pre_ans_str = \"장미_점박이응애병\"\n",
    "    elif pre_ans == 2: pre_ans_str = \"장미_흰가루병\"\n",
    "    elif pre_ans == 3: pre_ans_str = \"토마토_궤양병\"\n",
    "    elif pre_ans == 4: pre_ans_str = \"토마토_잎곰팡이병\"\n",
    "    elif pre_ans == 5: pre_ans_str = \"토마토_아메리카잎굴파리병\"\n",
    "    if i[0] >= 0.8 : \n",
    "        print(\"해당 \"+filenames[cnt].split(\"\\\\\")[1]+\"이미지는 \"+pre_ans_str+\"일 확률이 %.2f%%로 진단됩니다.\" % (i[0]*100))\n",
    "#         db.diagnosis.update({'pestName': 'pre_ans_str'}, {'percentage' : 'i[0]*100'})\n",
    "#         db.diagnosis.update({pestName: \"pre_ans_str\"}, {percentage : \"i[0]*100\"})\n",
    "        db.diagnosis.update({'pestName': ''}, {\"$set\": {'pestName': \"\"+pre_ans_str, 'percentage' : \"%.2f%%\"%(i[0]*100)}})\n",
    "\n",
    "\n",
    "        \n",
    "    if i[1] >= 0.8: \n",
    "        print(\"해당 \"+filenames[cnt].split(\"\\\\\")[1]+\"이미지는 \"+pre_ans_str+\"일 확률이 %.2f%%로 진단됩니다.\" % (i[1]*100))\n",
    "#         db.diagnosis.update({'pestName': 'pre_ans_str'}, {'percentage' : 'i[1]*100'})\n",
    "#         db.diagnosis.update({pestName: \"pre_ans_str\"}, {percentage : \"i[1]*100\"})\n",
    "        db.diagnosis.update({'pestName': ''}, {\"$set\": {'pestName': \"\"+pre_ans_str, 'percentage' : \"%.2f%%\"%(i[1]*100)}})\n",
    "\n",
    "\n",
    "        \n",
    "    if i[2] >= 0.8: \n",
    "        print(\"해당 \"+filenames[cnt].split(\"\\\\\")[1]+\"이미지는 \"+pre_ans_str+\"일 확률이 %.2f%%로진단됩니다.\" % (i[2]*100))\n",
    "#         db.diagnosis.update({'pestName': 'pre_ans_str'}, {'percentage' : 'i[2]*100'})\n",
    "#         db.diagnosis.update({pestName: \"pre_ans_str\"}, {percentage : \"i[2]*100\"})\n",
    "        db.diagnosis.update({'pestName': ''}, {\"$set\": {'pestName': \"\"+pre_ans_str, 'percentage' : \"%.2f%%\"%(i[2]*100)}})\n",
    "\n",
    "\n",
    "        \n",
    "    if i[3] >= 0.8: \n",
    "        print(\"해당 \"+filenames[cnt].split(\"\\\\\")[1]+\"이미지는 \"+pre_ans_str+\"일 확률이 %.2f%%로 진단됩니다.\" % (i[3]*100))\n",
    "#         db.diagnosis.update({'pestName': 'pre_ans_str'}, {'percentage' : 'i[3]*100'})\n",
    "#         db.diagnosis.update({pestName: \"pre_ans_str\"}, {percentage : \"i[3]*100\"})\n",
    "        db.diagnosis.update({'pestName': ''}, {\"$set\": {'pestName': \"\"+pre_ans_str, 'percentage' : \"%.2f%%\"%(i[3]*100)}})\n",
    "\n",
    "\n",
    "        \n",
    "    if i[4] >= 0.8: \n",
    "        print(\"해당 \"+filenames[cnt].split(\"\\\\\")[1]+\"이미지는 \"+pre_ans_str+\"일 확률이 %.2f%%로 진단됩니다.\" % (i[4]*100))\n",
    "#         db.diagnosis.update({'pestName': 'pre_ans_str'}, {'percentage' : 'i[3]*100'})\n",
    "#         db.diagnosis.update({pestName: \"pre_ans_str\"}, {percentage : \"i[4]*100\"})\n",
    "        db.diagnosis.update({'pestName': ''}, {\"$set\": {'pestName': \"\"+pre_ans_str, 'percentage' : \"%.2f%%\"%(i[4]*100)}})\n",
    "\n",
    "        \n",
    "    if i[5] >= 0.8: \n",
    "        print(\"해당 \"+filenames[cnt].split(\"\\\\\")[1]+\"이미지는 \"+pre_ans_str+\"일 확률이 %.2f%%로 진단됩니다.\" % (i[5]*100))\n",
    "#         db.diagnosis.update({'pestName': 'pre_ans_str'}, {'percentage' : 'i[5]*100'})\n",
    "#         db.diagnosis.update({pestName: \"pre_ans_str\"}, {percentage : \"i[5]*100\"})\n",
    "        db.diagnosis.update({'pestName': ''}, {\"$set\": {'pestName': \"\"+pre_ans_str, 'percentage' : \"%.2f%%\"%(i[5]*100)}})\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "    cnt += 1\n",
    "    # print(i.argmax()) #얘가 레이블 [1. 0. 0.] 이런식으로 되어 있는 것을 숫자로 바꿔주는 것.\n",
    "    # 즉 얘랑, 나중에 카테고리 데이터 불러와서 카테고리랑 비교를 해서 같으면 맞는거고, 아니면 틀린거로 취급하면 된다.\n",
    "    # 이걸 한 것은 _4.py에.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "비록 데이터가 적지만 그래도 나름 학습이 잘 되었습니다.\n",
    "\n",
    "하지만 **validation data와 test data가 나뉘어져 있지 않습니다.**\n",
    "\n",
    "이는 매우 위험한 시도입니다. 왜냐하면 검증 단계에서 테스트 데이터를 사용했는데 또 마지막에 정확도 검출 시 test_data를 사용합니다.\n",
    "\n",
    "데이터가 충분하다면 이런짓은 하지 않는게 좋습니다!\n",
    "\n",
    "하지만 새로운 데이터에 대한 예측은 그래도 잘 하는군요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "import base64\n",
    "from pymongo import MongoClient\n",
    "\n",
    "client = MongoClient(\"k4a305.p.ssafy.io:27017\")\n",
    "db = client.test\n",
    "collection = db.diagnosis\n",
    "    \n",
    "doc = collection.find({})\n",
    "    \n",
    "for i in doc:\n",
    "    \n",
    "    print(\"cropName : \" + i[\"cropName\"] + \"\\r\\n\" + \"img : \" + i[\"img\"])\n",
    "    \n",
    "    str1 = i[\"img\"] \n",
    "    text_base64 = str1\n",
    "    bytes_base64 = text_base64.encode()\n",
    "    data = base64.b64decode(bytes_base64)\n",
    "    test_dir = \"multi_img_data/imgs_others/test/\"\n",
    "    open(test_dir+'image.png', 'wb').write(data)\n",
    "    \n",
    "\n",
    "#     str1 = i[\"img\"] \n",
    "#     from wand.image import Image\n",
    "#     with Image(filename='inline:data:image/png;base64, '+str1) as img:\n",
    "#         img.save(filename='result.png')\n",
    "\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "metadata": {
   "interpreter": {
    "hash": "04635d289a519a1410467dd0afb0db42f9184808881ca68b2eb5a687a20a5a94"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
